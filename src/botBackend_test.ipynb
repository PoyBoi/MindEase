{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook exists to test fuctions and classes for the chatGPT bot, so i don't have to waste tokens on each iterative file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = open(r\"C:\\TheGoodShit\\PythonProject\\key.txt\", \"r\").read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testResponse = openai.ChatCompletion.create(\n",
    "#     model = \"davinci\",\n",
    "#     messages = [{\"role\":\"user\", \"content\":\"Hey GPT, tell me the importance of life.\"}]\n",
    "# )\n",
    "\n",
    "# print(testResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': \" Hey, I'm sorry to hear that. Why are you sad, if you don't mind me asking?\", 'conversation': {'generated_responses': [\" Hey, I'm sorry to hear that. Why are you sad, if you don't mind me asking?\"], 'past_user_inputs': ['Hey (I am sad but do not mention it)']}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/blenderbot-400M-distill\"\n",
    "headers = {\"Authorization\": \"Bearer <HF ID>\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": {\n",
    "\t\t# \"past_user_inputs\": [\"Which movie is the best ?\", \"Can you explain why ?\"],\n",
    "\t\t# \"generated_responses\": [\"It's Die Hard for sure.\", \"I think it's because it's based on a novel by James Fenimore Cooper.\"],\n",
    "\t\t\"text\": \"Hey (I am sad but do not mention it)\"\n",
    "\t},\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# import joblib\n",
    "\n",
    "# REPO_ID = \"BlenderBot\"\n",
    "# FILENAME = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "# model = joblib.load(\n",
    "#     hf_hub_download(repo_id=\"eaaf64e\", filename=\"facebook/blenderbot-400M-distill\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and setup the model and tokenizer\n",
    "model_name = 'facebook/blenderbot-400M-distill'\n",
    "#instantiate the tokenizer and the model itself on the model name.\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71066fbcdf38ea498a64010a176fff13046cd434e9747a132f7617453b6ef616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
